{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd09bfac",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-09T12:10:55.837321Z",
     "iopub.status.busy": "2025-12-09T12:10:55.836912Z",
     "iopub.status.idle": "2025-12-09T12:10:57.759350Z",
     "shell.execute_reply": "2025-12-09T12:10:57.758239Z"
    },
    "papermill": {
     "duration": 1.928093,
     "end_time": "2025-12-09T12:10:57.761072",
     "exception": false,
     "start_time": "2025-12-09T12:10:55.832979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/train.csv\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d14f661b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:10:57.767998Z",
     "iopub.status.busy": "2025-12-09T12:10:57.767376Z",
     "iopub.status.idle": "2025-12-09T12:16:10.567710Z",
     "shell.execute_reply": "2025-12-09T12:16:10.566773Z"
    },
    "papermill": {
     "duration": 312.806079,
     "end_time": "2025-12-09T12:16:10.569533",
     "exception": false,
     "start_time": "2025-12-09T12:10:57.763454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train shape: (1460, 81), Test shape: (1459, 80)\n",
      "Combined shape: (2917, 79)\n",
      "Target encoding: Neighborhood\n",
      "Target encoding: Exterior1st\n",
      "Target encoding: Exterior2nd\n",
      "Target encoding: SaleType\n",
      "Target encoding: MSSubClass\n",
      "Found 26 skewed numeric features to transform\n",
      "Shape after get_dummies: (2917, 203)\n",
      "Train features: (1458, 203) Test features: (1459, 203)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:11:06,931] A new study created in memory with name: no-name-8851b36e-d979-4502-b5b9-07db67bf2168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting LightGBM Optuna tuning and bagged training (50 trials Optuna)...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's rmse: 0.142346\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's rmse: 0.14751\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:11:09,825] Trial 0 finished with value: 0.1408480243976647 and parameters: {'learning_rate': 0.01184431975182039, 'num_leaves': 192, 'min_child_samples': 148, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.4936111842654619, 'reg_alpha': 2.5348407664333426e-07, 'reg_lambda': 3.3323645788192616e-08}. Best is trial 0 with value: 0.1408480243976647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's rmse: 0.132689\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1213]\tvalid_0's rmse: 0.14232\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1630]\tvalid_0's rmse: 0.145241\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:11:11,765] Trial 1 finished with value: 0.1404213776728466 and parameters: {'learning_rate': 0.03674059202635224, 'num_leaves': 128, 'min_child_samples': 143, 'subsample': 0.5102922471479012, 'colsample_bytree': 0.9819459112971965, 'reg_alpha': 0.31044435499483225, 'reg_lambda': 8.148018307012941e-07}. Best is trial 1 with value: 0.1404213776728466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[936]\tvalid_0's rmse: 0.133703\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1979]\tvalid_0's rmse: 0.134057\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's rmse: 0.133832\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:11:17,085] Trial 2 finished with value: 0.12976129999547228 and parameters: {'learning_rate': 0.007599674150654906, 'num_leaves': 53, 'min_child_samples': 64, 'subsample': 0.762378215816119, 'colsample_bytree': 0.6591670111852694, 'reg_alpha': 4.17890272377219e-06, 'reg_lambda': 0.0032112643094417484}. Best is trial 2 with value: 0.12976129999547228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1681]\tvalid_0's rmse: 0.121396\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's rmse: 0.135217\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1999]\tvalid_0's rmse: 0.138091\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:11:21,967] Trial 3 finished with value: 0.1325865130232625 and parameters: {'learning_rate': 0.006893882309676883, 'num_leaves': 72, 'min_child_samples': 76, 'subsample': 0.728034992108518, 'colsample_bytree': 0.8711055768358081, 'reg_alpha': 6.267062696005991e-07, 'reg_lambda': 0.00042472707398058225}. Best is trial 2 with value: 0.12976129999547228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1810]\tvalid_0's rmse: 0.124452\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1159]\tvalid_0's rmse: 0.14391\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[873]\tvalid_0's rmse: 0.153128\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:11:23,428] Trial 4 finished with value: 0.1453482386356243 and parameters: {'learning_rate': 0.019560708142748476, 'num_leaves': 28, 'min_child_samples': 124, 'subsample': 0.5852620618436457, 'colsample_bytree': 0.43903095579116774, 'reg_alpha': 3.4671276804481113, 'reg_lambda': 4.905556676028774}. Best is trial 2 with value: 0.12976129999547228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1263]\tvalid_0's rmse: 0.139006\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[306]\tvalid_0's rmse: 0.129634\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[672]\tvalid_0's rmse: 0.132565\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:11:26,661] Trial 5 finished with value: 0.12672776764598018 and parameters: {'learning_rate': 0.03216379996424947, 'num_leaves': 75, 'min_child_samples': 24, 'subsample': 0.8421165132560784, 'colsample_bytree': 0.6640914962437607, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574}. Best is trial 5 with value: 0.12672776764598018.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's rmse: 0.117984\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1992]\tvalid_0's rmse: 0.13266\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's rmse: 0.135128\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:11:33,086] Trial 6 finished with value: 0.12881952506973135 and parameters: {'learning_rate': 0.00541200919075048, 'num_leaves': 184, 'min_child_samples': 55, 'subsample': 0.831261142176991, 'colsample_bytree': 0.5870266456536466, 'reg_alpha': 0.0004793052550782129, 'reg_lambda': 0.0008325158565947976}. Best is trial 5 with value: 0.12672776764598018.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's rmse: 0.118671\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's rmse: 0.146383\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1998]\tvalid_0's rmse: 0.152293\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:11:35,945] Trial 7 finished with value: 0.1462758585882156 and parameters: {'learning_rate': 0.007652872182750091, 'num_leaves': 195, 'min_child_samples': 156, 'subsample': 0.9697494707820946, 'colsample_bytree': 0.9368964102565893, 'reg_alpha': 0.002404915432737351, 'reg_lambda': 1.9809253750493907}. Best is trial 5 with value: 0.12672776764598018.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[1997]\tvalid_0's rmse: 0.140152\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1996]\tvalid_0's rmse: 0.125558\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1578]\tvalid_0's rmse: 0.134975\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1347]\tvalid_0's rmse: 0.116018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:11:53,347] Trial 8 finished with value: 0.12551693637613778 and parameters: {'learning_rate': 0.006130028679593762, 'num_leaves': 55, 'min_child_samples': 13, 'subsample': 0.6626651653816322, 'colsample_bytree': 0.6332063738136893, 'reg_alpha': 2.7678419414850017e-06, 'reg_lambda': 0.28749982347407854}. Best is trial 8 with value: 0.12551693637613778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1995]\tvalid_0's rmse: 0.141366\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1999]\tvalid_0's rmse: 0.141941\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:11:56,783] Trial 9 finished with value: 0.13859128857091554 and parameters: {'learning_rate': 0.011369027867815908, 'num_leaves': 70, 'min_child_samples': 111, 'subsample': 0.5704621124873813, 'colsample_bytree': 0.8813181884524238, 'reg_alpha': 4.6876566400928895e-08, 'reg_lambda': 7.620481786158549}. Best is trial 8 with value: 0.12551693637613778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1663]\tvalid_0's rmse: 0.132467\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's rmse: 0.144453\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1996]\tvalid_0's rmse: 0.155144\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:11:58,950] Trial 10 finished with value: 0.14795692657012496 and parameters: {'learning_rate': 0.01631673880141291, 'num_leaves': 120, 'min_child_samples': 195, 'subsample': 0.6734254457033109, 'colsample_bytree': 0.784053101480534, 'reg_alpha': 2.6462851656372712e-05, 'reg_lambda': 0.03743708770436097}. Best is trial 8 with value: 0.12551693637613778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's rmse: 0.144274\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[337]\tvalid_0's rmse: 0.131352\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's rmse: 0.139202\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:12:05,880] Trial 11 finished with value: 0.1301998556265351 and parameters: {'learning_rate': 0.0471105528215639, 'num_leaves': 99, 'min_child_samples': 5, 'subsample': 0.9153368210114128, 'colsample_bytree': 0.6876941210333852, 'reg_alpha': 1.4745057636438337e-08, 'reg_lambda': 9.979820650110262e-06}. Best is trial 8 with value: 0.12551693637613778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's rmse: 0.120046\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[600]\tvalid_0's rmse: 0.123072\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[717]\tvalid_0's rmse: 0.130495\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:12:09,702] Trial 12 finished with value: 0.12182866238311672 and parameters: {'learning_rate': 0.02649072125632022, 'num_leaves': 23, 'min_child_samples': 7, 'subsample': 0.8836877669280698, 'colsample_bytree': 0.5686424561901412, 'reg_alpha': 1.638652911999463e-05, 'reg_lambda': 0.06642180887386759}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[413]\tvalid_0's rmse: 0.111918\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[538]\tvalid_0's rmse: 0.131277\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[823]\tvalid_0's rmse: 0.132984\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:12:12,893] Trial 13 finished with value: 0.12727936878146962 and parameters: {'learning_rate': 0.024462824828100804, 'num_leaves': 23, 'min_child_samples': 35, 'subsample': 0.6738167152482913, 'colsample_bytree': 0.549852781088597, 'reg_alpha': 2.706829617737318e-05, 'reg_lambda': 0.025574091808629934}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[625]\tvalid_0's rmse: 0.117577\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1325]\tvalid_0's rmse: 0.127773\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[333]\tvalid_0's rmse: 0.136175\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:12:22,137] Trial 14 finished with value: 0.12618478207028527 and parameters: {'learning_rate': 0.022430334329203112, 'num_leaves': 48, 'min_child_samples': 5, 'subsample': 0.910381099702518, 'colsample_bytree': 0.7715007264424556, 'reg_alpha': 0.009346690403461715, 'reg_lambda': 0.19329039126385797}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[566]\tvalid_0's rmse: 0.114606\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1405]\tvalid_0's rmse: 0.136008\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1598]\tvalid_0's rmse: 0.135639\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:12:25,609] Trial 15 finished with value: 0.13211486967757244 and parameters: {'learning_rate': 0.012204795821778594, 'num_leaves': 152, 'min_child_samples': 84, 'subsample': 0.690166470658845, 'colsample_bytree': 0.5814195687349474, 'reg_alpha': 2.0249298616973253e-05, 'reg_lambda': 0.4632722683442077}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1181]\tvalid_0's rmse: 0.124698\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[371]\tvalid_0's rmse: 0.13246\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[635]\tvalid_0's rmse: 0.131528\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:12:27,818] Trial 16 finished with value: 0.12724073641703357 and parameters: {'learning_rate': 0.0297289127588853, 'num_leaves': 42, 'min_child_samples': 42, 'subsample': 0.6140247418592039, 'colsample_bytree': 0.4342399765731927, 'reg_alpha': 1.6962134636528383e-06, 'reg_lambda': 0.012582829412955517}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[448]\tvalid_0's rmse: 0.117734\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[741]\tvalid_0's rmse: 0.130257\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[830]\tvalid_0's rmse: 0.132947\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:12:32,793] Trial 17 finished with value: 0.12758738643218978 and parameters: {'learning_rate': 0.014440179270617186, 'num_leaves': 94, 'min_child_samples': 23, 'subsample': 0.8805304594988683, 'colsample_bytree': 0.7597011029541516, 'reg_alpha': 0.00029837177996093017, 'reg_lambda': 0.2225505820447944}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[423]\tvalid_0's rmse: 0.119557\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1895]\tvalid_0's rmse: 0.137176\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's rmse: 0.137605\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:12:37,164] Trial 18 finished with value: 0.13353470542943693 and parameters: {'learning_rate': 0.00969590997367539, 'num_leaves': 20, 'min_child_samples': 90, 'subsample': 0.9734024632067818, 'colsample_bytree': 0.5220872424731229, 'reg_alpha': 0.03488853762413075, 'reg_lambda': 1.6807865461953592e-05}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1490]\tvalid_0's rmse: 0.125823\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1998]\tvalid_0's rmse: 0.13363\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's rmse: 0.1344\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:12:43,362] Trial 19 finished with value: 0.12906150641441996 and parameters: {'learning_rate': 0.005105864300487163, 'num_leaves': 60, 'min_child_samples': 53, 'subsample': 0.7550429827211348, 'colsample_bytree': 0.618182084819684, 'reg_alpha': 0.000461430574564604, 'reg_lambda': 0.7330439339261977}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[1999]\tvalid_0's rmse: 0.119155\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's rmse: 0.130002\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[348]\tvalid_0's rmse: 0.132506\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:12:45,496] Trial 20 finished with value: 0.12637534704806022 and parameters: {'learning_rate': 0.049565652127000835, 'num_leaves': 43, 'min_child_samples': 28, 'subsample': 0.632035183231185, 'colsample_bytree': 0.48987918650312734, 'reg_alpha': 5.788893629523687e-06, 'reg_lambda': 0.07286199163509512}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[241]\tvalid_0's rmse: 0.116618\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[411]\tvalid_0's rmse: 0.127397\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[650]\tvalid_0's rmse: 0.135604\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:12:50,673] Trial 21 finished with value: 0.12629306611172364 and parameters: {'learning_rate': 0.02121863340126876, 'num_leaves': 38, 'min_child_samples': 10, 'subsample': 0.8993508503697909, 'colsample_bytree': 0.7597217710692115, 'reg_alpha': 0.011419118668490474, 'reg_lambda': 0.005837958400294648}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[425]\tvalid_0's rmse: 0.115878\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[747]\tvalid_0's rmse: 0.131568\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[595]\tvalid_0's rmse: 0.137494\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:12:57,055] Trial 22 finished with value: 0.13008517294790792 and parameters: {'learning_rate': 0.026752775353518873, 'num_leaves': 85, 'min_child_samples': 6, 'subsample': 0.925919821734341, 'colsample_bytree': 0.814425417766067, 'reg_alpha': 0.07199025999281494, 'reg_lambda': 0.17017838353680553}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[303]\tvalid_0's rmse: 0.121193\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[698]\tvalid_0's rmse: 0.134005\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[996]\tvalid_0's rmse: 0.13522\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:13:00,712] Trial 23 finished with value: 0.12968697560898645 and parameters: {'learning_rate': 0.018640000535454518, 'num_leaves': 58, 'min_child_samples': 39, 'subsample': 0.9990727807248359, 'colsample_bytree': 0.7259727856914828, 'reg_alpha': 0.00015532180495409075, 'reg_lambda': 0.8855166830509574}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[732]\tvalid_0's rmse: 0.119837\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[392]\tvalid_0's rmse: 0.125937\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's rmse: 0.134327\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:13:03,627] Trial 24 finished with value: 0.1255347268513491 and parameters: {'learning_rate': 0.03954461069573503, 'num_leaves': 38, 'min_child_samples': 14, 'subsample': 0.8566205022574471, 'colsample_bytree': 0.6267110549840949, 'reg_alpha': 0.005752992654493046, 'reg_lambda': 0.0028993165757422233}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's rmse: 0.11634\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[204]\tvalid_0's rmse: 0.128512\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[399]\tvalid_0's rmse: 0.131229\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:13:06,137] Trial 25 finished with value: 0.12609769546668767 and parameters: {'learning_rate': 0.04021644795304806, 'num_leaves': 33, 'min_child_samples': 22, 'subsample': 0.849985130638782, 'colsample_bytree': 0.6067448748725277, 'reg_alpha': 8.306630840098371e-05, 'reg_lambda': 5.310814696851245e-05}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's rmse: 0.118553\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[434]\tvalid_0's rmse: 0.134556\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[978]\tvalid_0's rmse: 0.132636\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:13:08,118] Trial 26 finished with value: 0.13068901779389588 and parameters: {'learning_rate': 0.03375486414065594, 'num_leaves': 62, 'min_child_samples': 67, 'subsample': 0.8106452018417596, 'colsample_bytree': 0.6305309383813317, 'reg_alpha': 0.0015787857536935365, 'reg_lambda': 0.0015118020050006102}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[508]\tvalid_0's rmse: 0.124875\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[336]\tvalid_0's rmse: 0.135937\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[402]\tvalid_0's rmse: 0.140255\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:13:09,025] Trial 27 finished with value: 0.13400449233472256 and parameters: {'learning_rate': 0.041624218751452405, 'num_leaves': 34, 'min_child_samples': 44, 'subsample': 0.8638682726563433, 'colsample_bytree': 0.5499419110771834, 'reg_alpha': 2.2301008741801613, 'reg_lambda': 0.010347315060523932}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[372]\tvalid_0's rmse: 0.125817\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[552]\tvalid_0's rmse: 0.126896\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[441]\tvalid_0's rmse: 0.130675\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:13:11,700] Trial 28 finished with value: 0.12492891297985541 and parameters: {'learning_rate': 0.027904853677610513, 'num_leaves': 20, 'min_child_samples': 20, 'subsample': 0.7179634336973011, 'colsample_bytree': 0.7032366692208358, 'reg_alpha': 1.3090640287766155e-06, 'reg_lambda': 0.00015829879977636877}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[472]\tvalid_0's rmse: 0.117217\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's rmse: 0.143211\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1553]\tvalid_0's rmse: 0.154121\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:13:13,759] Trial 29 finished with value: 0.1466757079304451 and parameters: {'learning_rate': 0.028385516761651786, 'num_leaves': 147, 'min_child_samples': 196, 'subsample': 0.7894584787235704, 'colsample_bytree': 0.7134119067783999, 'reg_alpha': 3.8852279315531197e-07, 'reg_lambda': 7.437556571189244e-07}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[1993]\tvalid_0's rmse: 0.142695\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[836]\tvalid_0's rmse: 0.133091\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1446]\tvalid_0's rmse: 0.132029\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:13:17,211] Trial 30 finished with value: 0.12781617556426172 and parameters: {'learning_rate': 0.015031318764010218, 'num_leaves': 22, 'min_child_samples': 54, 'subsample': 0.7174622701471877, 'colsample_bytree': 0.5132721760558991, 'reg_alpha': 1.8658909166738798e-06, 'reg_lambda': 1.5777530655240928e-08}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[760]\tvalid_0's rmse: 0.118329\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[405]\tvalid_0's rmse: 0.1272\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[277]\tvalid_0's rmse: 0.135555\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:13:20,544] Trial 31 finished with value: 0.12638539066656754 and parameters: {'learning_rate': 0.03703660355731476, 'num_leaves': 45, 'min_child_samples': 16, 'subsample': 0.8033220135200155, 'colsample_bytree': 0.6519841671032148, 'reg_alpha': 1.0464735543760025e-05, 'reg_lambda': 0.0001353045009901117}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's rmse: 0.116401\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[477]\tvalid_0's rmse: 0.131428\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[706]\tvalid_0's rmse: 0.133148\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:13:23,627] Trial 32 finished with value: 0.12821016234454782 and parameters: {'learning_rate': 0.025787687319496377, 'num_leaves': 33, 'min_child_samples': 31, 'subsample': 0.7734329668571363, 'colsample_bytree': 0.7001168932990597, 'reg_alpha': 1.5345306012846431e-06, 'reg_lambda': 1.832951925012197e-06}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[435]\tvalid_0's rmse: 0.120055\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[511]\tvalid_0's rmse: 0.125154\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[517]\tvalid_0's rmse: 0.131656\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:13:27,363] Trial 33 finished with value: 0.12354585473771769 and parameters: {'learning_rate': 0.032800657503699496, 'num_leaves': 54, 'min_child_samples': 19, 'subsample': 0.5030969143062598, 'colsample_bytree': 0.4727983939345852, 'reg_alpha': 1.2921398868966695e-07, 'reg_lambda': 0.0022273893768143295}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's rmse: 0.113828\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[373]\tvalid_0's rmse: 0.133063\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[774]\tvalid_0's rmse: 0.132303\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:13:30,094] Trial 34 finished with value: 0.12716129538590695 and parameters: {'learning_rate': 0.02327421727742462, 'num_leaves': 83, 'min_child_samples': 44, 'subsample': 0.537282528194097, 'colsample_bytree': 0.46924876285154077, 'reg_alpha': 2.9936787073789606e-08, 'reg_lambda': 0.05451537164151006}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[716]\tvalid_0's rmse: 0.116117\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1003]\tvalid_0's rmse: 0.13165\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1512]\tvalid_0's rmse: 0.130838\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:13:33,204] Trial 35 finished with value: 0.12786152120566407 and parameters: {'learning_rate': 0.01784333899508618, 'num_leaves': 59, 'min_child_samples': 66, 'subsample': 0.5051742194845482, 'colsample_bytree': 0.4037073404094232, 'reg_alpha': 1.1825033541534651e-07, 'reg_lambda': 8.820406154481899e-05}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[965]\tvalid_0's rmse: 0.121097\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[566]\tvalid_0's rmse: 0.127318\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[544]\tvalid_0's rmse: 0.133968\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:13:37,470] Trial 36 finished with value: 0.1262889343780487 and parameters: {'learning_rate': 0.03126535640679509, 'num_leaves': 52, 'min_child_samples': 18, 'subsample': 0.6335062897887276, 'colsample_bytree': 0.5575293012241447, 'reg_alpha': 5.002979575303281e-07, 'reg_lambda': 0.0016585197199731256}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's rmse: 0.117581\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1996]\tvalid_0's rmse: 0.143811\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's rmse: 0.149104\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:13:40,109] Trial 37 finished with value: 0.14316887199258277 and parameters: {'learning_rate': 0.00972328140181575, 'num_leaves': 71, 'min_child_samples': 154, 'subsample': 0.7172496379935862, 'colsample_bytree': 0.4605360036812139, 'reg_alpha': 1.0920779196532624e-07, 'reg_lambda': 0.0007432478686767247}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's rmse: 0.136591\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1864]\tvalid_0's rmse: 0.129277\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1990]\tvalid_0's rmse: 0.13306\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:13:49,246] Trial 38 finished with value: 0.12710140732037642 and parameters: {'learning_rate': 0.006843808628586769, 'num_leaves': 109, 'min_child_samples': 28, 'subsample': 0.5368725043336398, 'colsample_bytree': 0.6717889568266363, 'reg_alpha': 2.8526213524760566e-06, 'reg_lambda': 2.2046307841125232}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1223]\tvalid_0's rmse: 0.118968\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1203]\tvalid_0's rmse: 0.141278\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1702]\tvalid_0's rmse: 0.143467\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:13:51,169] Trial 39 finished with value: 0.13903192963544622 and parameters: {'learning_rate': 0.03510364563935325, 'num_leaves': 50, 'min_child_samples': 139, 'subsample': 0.5966145915433451, 'colsample_bytree': 0.5170253028171239, 'reg_alpha': 5.726111432588675e-07, 'reg_lambda': 0.0003289645567565774}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1004]\tvalid_0's rmse: 0.13235\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1999]\tvalid_0's rmse: 0.134067\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's rmse: 0.136602\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:13:55,936] Trial 40 finished with value: 0.13117822095388046 and parameters: {'learning_rate': 0.005982435158337756, 'num_leaves': 28, 'min_child_samples': 75, 'subsample': 0.6516175963963075, 'colsample_bytree': 0.5853837037125632, 'reg_alpha': 7.263687716186585e-05, 'reg_lambda': 3.1492548674868804e-07}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[1997]\tvalid_0's rmse: 0.122866\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[456]\tvalid_0's rmse: 0.124545\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[372]\tvalid_0's rmse: 0.133166\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:13:57,967] Trial 41 finished with value: 0.12445639604934688 and parameters: {'learning_rate': 0.041068505849990646, 'num_leaves': 20, 'min_child_samples': 17, 'subsample': 0.7374821279913889, 'colsample_bytree': 0.649570058875891, 'reg_alpha': 9.2067745236923e-06, 'reg_lambda': 0.0035087115809016465}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's rmse: 0.115658\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[290]\tvalid_0's rmse: 0.128001\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[262]\tvalid_0's rmse: 0.135251\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:14:00,220] Trial 42 finished with value: 0.1267318908092195 and parameters: {'learning_rate': 0.045668639366504345, 'num_leaves': 29, 'min_child_samples': 17, 'subsample': 0.732747727015876, 'colsample_bytree': 0.7379803380743163, 'reg_alpha': 8.942881198140991e-06, 'reg_lambda': 0.005403803805595977}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's rmse: 0.116944\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[367]\tvalid_0's rmse: 0.129868\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[544]\tvalid_0's rmse: 0.132503\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:14:02,606] Trial 43 finished with value: 0.12728367467617804 and parameters: {'learning_rate': 0.029928053298916724, 'num_leaves': 21, 'min_child_samples': 32, 'subsample': 0.692578075364436, 'colsample_bytree': 0.6506075770877296, 'reg_alpha': 2.36757708049353e-07, 'reg_lambda': 0.01679260459998249}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[397]\tvalid_0's rmse: 0.11948\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1468]\tvalid_0's rmse: 0.14296\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1822]\tvalid_0's rmse: 0.15042\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:14:04,881] Trial 44 finished with value: 0.14327252192854345 and parameters: {'learning_rate': 0.02095599710662351, 'num_leaves': 29, 'min_child_samples': 172, 'subsample': 0.7453562805104493, 'colsample_bytree': 0.9991845595355717, 'reg_alpha': 9.131088143392257e-07, 'reg_lambda': 3.155833385720571e-05}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[1999]\tvalid_0's rmse: 0.136437\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[290]\tvalid_0's rmse: 0.128142\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[413]\tvalid_0's rmse: 0.136097\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:14:09,563] Trial 45 finished with value: 0.1276844271980503 and parameters: {'learning_rate': 0.04243260225541598, 'num_leaves': 179, 'min_child_samples': 13, 'subsample': 0.5614999224449386, 'colsample_bytree': 0.8053491634507463, 'reg_alpha': 3.9837678523509194e-05, 'reg_lambda': 0.0002058426780261696}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's rmse: 0.118814\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[605]\tvalid_0's rmse: 0.139244\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[670]\tvalid_0's rmse: 0.141133\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:14:10,901] Trial 46 finished with value: 0.13650376234338304 and parameters: {'learning_rate': 0.033708338908071796, 'num_leaves': 64, 'min_child_samples': 101, 'subsample': 0.7696502017720774, 'colsample_bytree': 0.6846877352914102, 'reg_alpha': 4.449453454799117e-06, 'reg_lambda': 0.10929928991810493}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[591]\tvalid_0's rmse: 0.129134\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid_0's rmse: 0.134658\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[544]\tvalid_0's rmse: 0.132883\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:14:12,767] Trial 47 finished with value: 0.12839800892143047 and parameters: {'learning_rate': 0.03674269070954363, 'num_leaves': 83, 'min_child_samples': 49, 'subsample': 0.8272034834891923, 'colsample_bytree': 0.5715784990704799, 'reg_alpha': 3.2704113210380186e-08, 'reg_lambda': 0.0008503155737173048}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[575]\tvalid_0's rmse: 0.117653\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1081]\tvalid_0's rmse: 0.130003\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1358]\tvalid_0's rmse: 0.133234\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:14:18,289] Trial 48 finished with value: 0.1269333782909717 and parameters: {'learning_rate': 0.013289543513718333, 'num_leaves': 43, 'min_child_samples': 34, 'subsample': 0.6984977041233017, 'colsample_bytree': 0.5992731499276404, 'reg_alpha': 1.4964852487826146e-05, 'reg_lambda': 0.0033588080354068277}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[921]\tvalid_0's rmse: 0.117563\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[531]\tvalid_0's rmse: 0.128628\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[724]\tvalid_0's rmse: 0.129155\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 12:14:21,547] Trial 49 finished with value: 0.12500559913006062 and parameters: {'learning_rate': 0.026373010902548025, 'num_leaves': 26, 'min_child_samples': 24, 'subsample': 0.6516047210107583, 'colsample_bytree': 0.5331071772915678, 'reg_alpha': 7.34875637057487e-08, 'reg_lambda': 0.025564299828799562}. Best is trial 12 with value: 0.12182866238311672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[326]\tvalid_0's rmse: 0.117235\n",
      "Optuna best params: {'learning_rate': 0.02649072125632022, 'num_leaves': 23, 'min_child_samples': 7, 'subsample': 0.8836877669280698, 'colsample_bytree': 0.5686424561901412, 'reg_alpha': 1.638652911999463e-05, 'reg_lambda': 0.06642180887386759}\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[555]\tvalid_0's rmse: 0.127225\n",
      "Seed 42 | Fold 1 LGB RMSE: 0.12722\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[715]\tvalid_0's rmse: 0.112152\n",
      "Seed 42 | Fold 2 LGB RMSE: 0.11215\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[679]\tvalid_0's rmse: 0.123639\n",
      "Seed 42 | Fold 3 LGB RMSE: 0.12364\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[791]\tvalid_0's rmse: 0.128592\n",
      "Seed 42 | Fold 4 LGB RMSE: 0.12859\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[446]\tvalid_0's rmse: 0.108514\n",
      "Seed 42 | Fold 5 LGB RMSE: 0.10851\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[420]\tvalid_0's rmse: 0.127937\n",
      "Seed 7 | Fold 1 LGB RMSE: 0.12794\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[588]\tvalid_0's rmse: 0.110704\n",
      "Seed 7 | Fold 2 LGB RMSE: 0.11070\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[464]\tvalid_0's rmse: 0.125068\n",
      "Seed 7 | Fold 3 LGB RMSE: 0.12507\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[350]\tvalid_0's rmse: 0.12805\n",
      "Seed 7 | Fold 4 LGB RMSE: 0.12805\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[448]\tvalid_0's rmse: 0.112633\n",
      "Seed 7 | Fold 5 LGB RMSE: 0.11263\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[785]\tvalid_0's rmse: 0.128472\n",
      "Seed 99 | Fold 1 LGB RMSE: 0.12847\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[580]\tvalid_0's rmse: 0.112189\n",
      "Seed 99 | Fold 2 LGB RMSE: 0.11219\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[564]\tvalid_0's rmse: 0.123393\n",
      "Seed 99 | Fold 3 LGB RMSE: 0.12339\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[293]\tvalid_0's rmse: 0.129356\n",
      "Seed 99 | Fold 4 LGB RMSE: 0.12936\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[379]\tvalid_0's rmse: 0.108603\n",
      "Seed 99 | Fold 5 LGB RMSE: 0.10860\n",
      "LightGBM OOF RMSE: 0.12007763034955074\n",
      "\n",
      "Training XGBoost...\n",
      "Fold 1 XGB RMSE: 0.12675\n",
      "Fold 2 XGB RMSE: 0.11263\n",
      "Fold 3 XGB RMSE: 0.12478\n",
      "Fold 4 XGB RMSE: 0.12411\n",
      "Fold 5 XGB RMSE: 0.10895\n",
      "XGBoost OOF RMSE: 0.11966677412761552\n",
      "\n",
      "Training CatBoost...\n",
      "Fold 1 CatBoost RMSE: 0.11749\n",
      "Fold 2 CatBoost RMSE: 0.11111\n",
      "Fold 3 CatBoost RMSE: 0.12038\n",
      "Fold 4 CatBoost RMSE: 0.12152\n",
      "Fold 5 CatBoost RMSE: 0.10335\n",
      "CatBoost OOF RMSE: 0.1149721614596735\n",
      "\n",
      "Training Ridge baseline...\n",
      "Fold 1 Ridge RMSE: 0.11608\n",
      "Fold 2 Ridge RMSE: 0.11329\n",
      "Fold 3 Ridge RMSE: 0.12428\n",
      "Fold 4 Ridge RMSE: 0.12016\n",
      "Fold 5 Ridge RMSE: 0.10011\n",
      "Ridge OOF RMSE: 0.11508419306808253\n",
      "\n",
      "Stacking meta-learner (Ridge)...\n",
      "Fold 1 Meta RMSE: 0.11580\n",
      "Fold 2 Meta RMSE: 0.10684\n",
      "Fold 3 Meta RMSE: 0.11948\n",
      "Fold 4 Meta RMSE: 0.11713\n",
      "Fold 5 Meta RMSE: 0.09903\n",
      "Meta OOF RMSE: 0.111922340283229\n",
      "\n",
      "Wrote submission.csv  ready to upload to Kaggle\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "house_prices_full_corrected.py\n",
    "Full single-file pipeline for Kaggle \"House Prices - Advanced Regression Techniques\".\n",
    "\n",
    "- Kaggle-friendly paths\n",
    "- Outlier handling\n",
    "- Missing-value handling\n",
    "- Feature engineering\n",
    "- Target-safe target encoding\n",
    "- Optuna tuning for LightGBM (50 trials)\n",
    "- Bagged LightGBM, robust XGBoost, optional CatBoost, Ridge baseline\n",
    "- Stacking meta-learner (Ridge)\n",
    "- Writes submission.csv\n",
    "\n",
    "Author: Generated for Santosh\n",
    "Date: 2025-12-09\n",
    "\"\"\"\n",
    "# ---------------------------\n",
    "# Imports & Settings\n",
    "# ---------------------------\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# optional imports will be attempted later\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Helpers\n",
    "# ---------------------------\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "def load_data_kaggle():\n",
    "    train_path = \"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\"\n",
    "    test_path = \"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\"\n",
    "    if not Path(train_path).exists() or not Path(test_path).exists():\n",
    "        raise FileNotFoundError(\"Dataset not found at Kaggle path. Adjust paths if running locally.\")\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def target_encode_kfold(trn_ser, tst_ser, target, n_splits=5, min_samples_leaf=20, smoothing=10, noise_level=0.01):\n",
    "    \"\"\"\n",
    "    K-fold target encoding (out-of-fold for train).\n",
    "    Returns: (train_encoded_series, test_encoded_series)\n",
    "    \"\"\"\n",
    "    oof = pd.Series(index=trn_ser.index, dtype=float)\n",
    "    kf_local = KFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    for tr_idx, val_idx in kf_local.split(trn_ser):\n",
    "        tr_vals = trn_ser.iloc[tr_idx]\n",
    "        tr_target = target.iloc[tr_idx]\n",
    "        averages = tr_target.groupby(tr_vals).agg(['mean', 'count'])\n",
    "        smoothing_val = 1 / (1 + np.exp(-(averages['count'] - min_samples_leaf) / smoothing))\n",
    "        prior = tr_target.mean()\n",
    "        averages['smoothed'] = prior * (1 - smoothing_val) + averages['mean'] * smoothing_val\n",
    "        mapping = averages['smoothed'].to_dict()\n",
    "        oof.iloc[val_idx] = trn_ser.iloc[val_idx].map(mapping).fillna(prior)\n",
    "    # Full-train mapping for test\n",
    "    averages = target.groupby(trn_ser).agg(['mean', 'count'])\n",
    "    smoothing_val = 1 / (1 + np.exp(-(averages['count'] - min_samples_leaf) / smoothing))\n",
    "    prior = target.mean()\n",
    "    averages['smoothed'] = prior * (1 - smoothing_val) + averages['mean'] * smoothing_val\n",
    "    mapping = averages['smoothed'].to_dict()\n",
    "    test_encoded = tst_ser.map(mapping).fillna(prior)\n",
    "    # Add small noise to reduce overfitting\n",
    "    oof = oof * (1 + noise_level * np.random.randn(len(oof)))\n",
    "    test_encoded = test_encoded * (1 + noise_level * np.random.randn(len(test_encoded)))\n",
    "    return oof, test_encoded\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Main pipeline\n",
    "# ---------------------------\n",
    "def main():\n",
    "    print(\"Loading data...\")\n",
    "    train, test = load_data_kaggle()\n",
    "    print(f\"Train shape: {train.shape}, Test shape: {test.shape}\")\n",
    "\n",
    "    # Store IDs\n",
    "    train_ID = train[\"Id\"].copy()\n",
    "    test_ID = test[\"Id\"].copy()\n",
    "\n",
    "    # Optional: remove obvious outliers (common trick)\n",
    "    train = train.drop(train[(train[\"GrLivArea\"] > 4000) & (train[\"SalePrice\"] < 300000)].index, errors=\"ignore\")\n",
    "\n",
    "    # Drop Id columns\n",
    "    train.drop([\"Id\"], axis=1, inplace=True)\n",
    "    test.drop([\"Id\"], axis=1, inplace=True)\n",
    "\n",
    "    # Target\n",
    "    train[\"SalePrice\"] = train[\"SalePrice\"].astype(float)\n",
    "    train[\"LogSalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "    y = train[\"LogSalePrice\"].reset_index(drop=True)\n",
    "\n",
    "    # Combine for consistent preprocessing\n",
    "    ntrain = train.shape[0]\n",
    "    all_data = pd.concat([train.drop([\"SalePrice\", \"LogSalePrice\"], axis=1), test], axis=0).reset_index(drop=True)\n",
    "    print(\"Combined shape:\", all_data.shape)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Missing data heuristics\n",
    "    # ---------------------------\n",
    "    none_cols = [\n",
    "        \"Alley\", \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinType2\",\n",
    "        \"FireplaceQu\", \"GarageType\", \"GarageFinish\", \"GarageQual\", \"GarageCond\",\n",
    "        \"PoolQC\", \"Fence\", \"MiscFeature\", \"MasVnrType\"\n",
    "    ]\n",
    "    for col in none_cols:\n",
    "        if col in all_data.columns:\n",
    "            all_data[col] = all_data[col].fillna(\"None\")\n",
    "\n",
    "    if \"GarageYrBlt\" in all_data.columns:\n",
    "        all_data[\"GarageYrBlt\"] = all_data[\"GarageYrBlt\"].fillna(0)\n",
    "\n",
    "    # Numeric fill with median\n",
    "    num_cols = all_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    for col in num_cols:\n",
    "        if all_data[col].isnull().sum() > 0:\n",
    "            all_data[col] = all_data[col].fillna(all_data[col].median())\n",
    "\n",
    "    # Categorical fill with mode\n",
    "    cat_cols = all_data.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "    for col in cat_cols:\n",
    "        if all_data[col].isnull().sum() > 0:\n",
    "            all_data[col] = all_data[col].fillna(all_data[col].mode()[0])\n",
    "\n",
    "    # ---------------------------\n",
    "    # Feature engineering\n",
    "    # ---------------------------\n",
    "    all_data[\"TotalSF\"] = all_data.get(\"TotalBsmtSF\", 0) + all_data.get(\"1stFlrSF\", 0) + all_data.get(\"2ndFlrSF\", 0)\n",
    "    all_data[\"TotalPorchSF\"] = (\n",
    "        all_data.get(\"OpenPorchSF\", 0)\n",
    "        + all_data.get(\"EnclosedPorch\", 0)\n",
    "        + all_data.get(\"3SsnPorch\", 0)\n",
    "        + all_data.get(\"ScreenPorch\", 0)\n",
    "    )\n",
    "\n",
    "    if \"YrSold\" in all_data.columns and \"YearBuilt\" in all_data.columns:\n",
    "        all_data[\"YrSold\"] = all_data[\"YrSold\"].astype(int)\n",
    "        all_data[\"YearBuilt\"] = all_data[\"YearBuilt\"].astype(int)\n",
    "        all_data[\"AgeAtSale\"] = all_data[\"YrSold\"] - all_data[\"YearBuilt\"]\n",
    "\n",
    "    if \"YearRemodAdd\" in all_data.columns and \"YrSold\" in all_data.columns:\n",
    "        all_data[\"YearsSinceRemod\"] = all_data[\"YrSold\"] - all_data[\"YearRemodAdd\"]\n",
    "\n",
    "    if \"GarageCars\" in all_data.columns and \"GarageArea\" in all_data.columns:\n",
    "        all_data[\"GarageCars_per_Area\"] = (all_data[\"GarageCars\"] + 0.001) / (all_data[\"GarageArea\"] + 0.001)\n",
    "\n",
    "    if \"OverallQual\" in all_data.columns and \"GrLivArea\" in all_data.columns:\n",
    "        all_data[\"Qual_by_Area\"] = all_data[\"OverallQual\"] * all_data[\"GrLivArea\"]\n",
    "\n",
    "    # ---------------------------\n",
    "    # Target encoding for chosen features\n",
    "    # ---------------------------\n",
    "    te_candidates = [f for f in [\"Neighborhood\", \"Exterior1st\", \"Exterior2nd\", \"SaleType\", \"MSSubClass\"] if f in all_data.columns]\n",
    "    for f in te_candidates:\n",
    "        print(\"Target encoding:\", f)\n",
    "        train_ser = all_data.loc[: ntrain - 1, f].reset_index(drop=True)\n",
    "        test_ser = all_data.loc[ntrain:, f].reset_index(drop=True)\n",
    "        tr_enc, te_enc = target_encode_kfold(train_ser, test_ser, target=y, n_splits=5, min_samples_leaf=50, smoothing=20, noise_level=0.01)\n",
    "        all_data.loc[: ntrain - 1, f + \"_te\"] = tr_enc.values\n",
    "        all_data.loc[ntrain:, f + \"_te\"] = te_enc.values\n",
    "\n",
    "    # ---------------------------\n",
    "    # Skew transform numeric features\n",
    "    # ---------------------------\n",
    "    numeric_feats = all_data.select_dtypes(include=[np.number]).columns\n",
    "    skewed_feats = all_data[numeric_feats].apply(lambda x: stats.skew(x.dropna())).sort_values(ascending=False)\n",
    "    skewness = pd.DataFrame({\"Skew\": skewed_feats})\n",
    "    skewed_features = skewness[abs(skewness[\"Skew\"]) > 0.75].index.tolist()\n",
    "    print(f\"Found {len(skewed_features)} skewed numeric features to transform\")\n",
    "    for feat in skewed_features:\n",
    "        try:\n",
    "            all_data[feat] = boxcox1p(all_data[feat], 0.15)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # ---------------------------\n",
    "    # Ordinal and small-cardinality encoding\n",
    "    # ---------------------------\n",
    "    ordinal_mappings = {\n",
    "        \"ExterQual\": {\"None\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "        \"ExterCond\": {\"None\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "        \"BsmtQual\": {\"None\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "        \"BsmtCond\": {\"None\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "        \"HeatingQC\": {\"None\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "        \"KitchenQual\": {\"None\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "        \"FireplaceQu\": {\"None\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "        \"GarageQual\": {\"None\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "        \"GarageCond\": {\"None\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "        \"PoolQC\": {\"None\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    }\n",
    "    for col, mapping in ordinal_mappings.items():\n",
    "        if col in all_data.columns:\n",
    "            all_data[col] = all_data[col].map(mapping).astype(int)\n",
    "\n",
    "    cat_cols = all_data.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "    for col in cat_cols:\n",
    "        if all_data[col].nunique() <= 6:\n",
    "            try:\n",
    "                le = LabelEncoder()\n",
    "                all_data[col] = le.fit_transform(all_data[col].astype(str))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # One-hot remaining categoricals\n",
    "    all_data = pd.get_dummies(all_data)\n",
    "    print(\"Shape after get_dummies:\", all_data.shape)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Split back\n",
    "    # ---------------------------\n",
    "    train_features = all_data[:ntrain].copy()\n",
    "    test_features = all_data[ntrain:].copy()\n",
    "    print(\"Train features:\", train_features.shape, \"Test features:\", test_features.shape)\n",
    "\n",
    "    # Align just in case\n",
    "    train_features, test_features = train_features.align(test_features, join=\"left\", axis=1, fill_value=0)\n",
    "\n",
    "    # ---------------------------\n",
    "    # CV setup\n",
    "    # ---------------------------\n",
    "    NFOLD = 5\n",
    "    kf = KFold(n_splits=NFOLD, shuffle=True, random_state=SEED)\n",
    "\n",
    "    n_train = train_features.shape[0]\n",
    "    n_test = test_features.shape[0]\n",
    "\n",
    "    # OOF and preds storage\n",
    "    oof_lgb = np.zeros(n_train)\n",
    "    pred_lgb = np.zeros(n_test)\n",
    "\n",
    "    oof_xgb = np.zeros(n_train)\n",
    "    pred_xgb = np.zeros(n_test)\n",
    "\n",
    "    oof_ridge = np.zeros(n_train)\n",
    "    pred_ridge = np.zeros(n_test)\n",
    "\n",
    "    # Optional CatBoost\n",
    "    use_catboost = False\n",
    "    try:\n",
    "        from catboost import CatBoostRegressor\n",
    "        use_catboost = True\n",
    "        oof_cat = np.zeros(n_train)\n",
    "        pred_cat = np.zeros(n_test)\n",
    "    except Exception:\n",
    "        use_catboost = False\n",
    "\n",
    "    # ---------------------------\n",
    "    # LightGBM: Optuna tuning (quick study) + bagging\n",
    "    # ---------------------------\n",
    "    print(\"\\nStarting LightGBM Optuna tuning and bagged training (50 trials Optuna)...\")\n",
    "    try:\n",
    "        import optuna\n",
    "\n",
    "        def lgb_objective(trial):\n",
    "            params = {\n",
    "                \"objective\": \"regression\",\n",
    "                \"metric\": \"rmse\",\n",
    "                \"boosting\": \"gbdt\",\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.05, log=True),\n",
    "                \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 200),\n",
    "                \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 200),\n",
    "                \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "                \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "                \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "                \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "                \"verbosity\": -1,\n",
    "                \"seed\": SEED,\n",
    "            }\n",
    "\n",
    "            kf_local = KFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "            cv_scores = []\n",
    "            for tr_idx, val_idx in kf_local.split(train_features):\n",
    "                X_tr = train_features.iloc[tr_idx]\n",
    "                X_val = train_features.iloc[val_idx]\n",
    "                y_tr = y.iloc[tr_idx]\n",
    "                y_val = y.iloc[val_idx]\n",
    "                dtrain = lgb.Dataset(X_tr, label=y_tr)\n",
    "                dval = lgb.Dataset(X_val, label=y_val)\n",
    "                model = lgb.train(\n",
    "                    params,\n",
    "                    dtrain,\n",
    "                    num_boost_round=2000,\n",
    "                    valid_sets=[dval],\n",
    "                    callbacks=[lgb.early_stopping(100), lgb.log_evaluation(period=0)],\n",
    "                )\n",
    "                best_it = model.best_iteration or 1000\n",
    "                preds = model.predict(X_val, num_iteration=best_it)\n",
    "                cv_scores.append(rmse(y_val, preds))\n",
    "            return np.mean(cv_scores)\n",
    "\n",
    "        study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(seed=SEED))\n",
    "        study.optimize(lgb_objective, n_trials=50, show_progress_bar=False)\n",
    "        print(\"Optuna best params:\", study.best_params)\n",
    "        # translate to best params\n",
    "        best_lgb_params = {\n",
    "            \"objective\": \"regression\",\n",
    "            \"metric\": \"rmse\",\n",
    "            \"boosting\": \"gbdt\",\n",
    "            \"learning_rate\": float(study.best_params[\"learning_rate\"]),\n",
    "            \"num_leaves\": int(study.best_params[\"num_leaves\"]),\n",
    "            \"min_child_samples\": int(study.best_params[\"min_child_samples\"]),\n",
    "            \"subsample\": float(study.best_params[\"subsample\"]),\n",
    "            \"colsample_bytree\": float(study.best_params[\"colsample_bytree\"]),\n",
    "            \"reg_alpha\": float(study.best_params[\"reg_alpha\"]),\n",
    "            \"reg_lambda\": float(study.best_params[\"reg_lambda\"]),\n",
    "            \"verbosity\": -1,\n",
    "            \"seed\": SEED,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(\"Optuna not available or failed, falling back to default LGB params. Error:\", e)\n",
    "        best_lgb_params = {\n",
    "            \"objective\": \"regression\",\n",
    "            \"metric\": \"rmse\",\n",
    "            \"boosting\": \"gbdt\",\n",
    "            \"learning_rate\": 0.01,\n",
    "            \"num_leaves\": 31,\n",
    "            \"min_child_samples\": 20,\n",
    "            \"subsample\": 0.8,\n",
    "            \"colsample_bytree\": 0.8,\n",
    "            \"reg_alpha\": 0.0,\n",
    "            \"reg_lambda\": 0.0,\n",
    "            \"verbosity\": -1,\n",
    "            \"seed\": SEED,\n",
    "        }\n",
    "\n",
    "    # Bagging seeds\n",
    "    lgb_seeds = [SEED, 7, 99]\n",
    "    for seed_i in lgb_seeds:\n",
    "        params = best_lgb_params.copy()\n",
    "        params[\"seed\"] = seed_i\n",
    "        fold_oof = np.zeros(n_train)\n",
    "        fold_pred = np.zeros(n_test)\n",
    "        for fold, (tr_idx, val_idx) in enumerate(kf.split(train_features)):\n",
    "            X_tr = train_features.iloc[tr_idx]\n",
    "            X_val = train_features.iloc[val_idx]\n",
    "            y_tr = y.iloc[tr_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "            dtrain = lgb.Dataset(X_tr, label=y_tr)\n",
    "            dval = lgb.Dataset(X_val, label=y_val)\n",
    "            model = lgb.train(\n",
    "                params,\n",
    "                dtrain,\n",
    "                num_boost_round=5000,\n",
    "                valid_sets=[dval],\n",
    "                callbacks=[lgb.early_stopping(200), lgb.log_evaluation(period=0)],\n",
    "            )\n",
    "            best_iter = model.best_iteration or 2000\n",
    "            fold_oof[val_idx] = model.predict(X_val, num_iteration=best_iter)\n",
    "            fold_pred += model.predict(test_features, num_iteration=best_iter) / NFOLD\n",
    "            print(f\"Seed {seed_i} | Fold {fold+1} LGB RMSE: {rmse(y_val, fold_oof[val_idx]):.5f}\")\n",
    "        # accumulate average across seeds\n",
    "        oof_lgb += fold_oof / len(lgb_seeds)\n",
    "        pred_lgb += fold_pred / len(lgb_seeds)\n",
    "\n",
    "    print(\"LightGBM OOF RMSE:\", rmse(y, oof_lgb))\n",
    "\n",
    "    # ---------------------------\n",
    "    # XGBoost (robust)\n",
    "    # ---------------------------\n",
    "    print(\"\\nTraining XGBoost...\")\n",
    "    params_xgb = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"max_depth\": 6,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"seed\": SEED,\n",
    "        \"verbosity\": 0,\n",
    "    }\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(train_features)):\n",
    "        X_tr = train_features.iloc[tr_idx]\n",
    "        X_val = train_features.iloc[val_idx]\n",
    "        y_tr = y.iloc[tr_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "        dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
    "        dval = xgb.DMatrix(X_val, label=y_val)\n",
    "        dtest = xgb.DMatrix(test_features)\n",
    "        clf = xgb.train(\n",
    "            params_xgb,\n",
    "            dtrain,\n",
    "            num_boost_round=10000,\n",
    "            evals=[(dtrain, \"train\"), (dval, \"eval\")],\n",
    "            early_stopping_rounds=200,\n",
    "            verbose_eval=False,\n",
    "        )\n",
    "        # robust best iter\n",
    "        best_iter = None\n",
    "        if hasattr(clf, \"best_iteration\") and clf.best_iteration is not None:\n",
    "            best_iter = int(clf.best_iteration)\n",
    "        elif hasattr(clf, \"best_ntree_limit\") and clf.best_ntree_limit is not None:\n",
    "            best_iter = int(clf.best_ntree_limit)\n",
    "        else:\n",
    "            best_iter = 10000\n",
    "        try:\n",
    "            oof_xgb[val_idx] = clf.predict(dval, iteration_range=(0, best_iter))\n",
    "            pred_xgb += clf.predict(dtest, iteration_range=(0, best_iter)) / NFOLD\n",
    "        except TypeError:\n",
    "            oof_xgb[val_idx] = clf.predict(dval, ntree_limit=best_iter)\n",
    "            pred_xgb += clf.predict(dtest, ntree_limit=best_iter) / NFOLD\n",
    "        print(f\"Fold {fold+1} XGB RMSE: {rmse(y_val, oof_xgb[val_idx]):.5f}\")\n",
    "    print(\"XGBoost OOF RMSE:\", rmse(y, oof_xgb))\n",
    "\n",
    "    # ---------------------------\n",
    "    # Optional CatBoost (if installed)\n",
    "    # ---------------------------\n",
    "    if use_catboost:\n",
    "        print(\"\\nTraining CatBoost...\")\n",
    "        from catboost import CatBoostRegressor\n",
    "        for fold, (tr_idx, val_idx) in enumerate(kf.split(train_features)):\n",
    "            X_tr = train_features.iloc[tr_idx]\n",
    "            X_val = train_features.iloc[val_idx]\n",
    "            y_tr = y.iloc[tr_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "            model = CatBoostRegressor(loss_function=\"RMSE\", iterations=3000, learning_rate=0.03, depth=6, random_seed=SEED, early_stopping_rounds=200, verbose=0)\n",
    "            model.fit(X_tr, y_tr, eval_set=(X_val, y_val))\n",
    "            oof_cat[val_idx] = model.predict(X_val)\n",
    "            pred_cat += model.predict(test_features) / NFOLD\n",
    "            print(f\"Fold {fold+1} CatBoost RMSE: {rmse(y_val, oof_cat[val_idx]):.5f}\")\n",
    "        print(\"CatBoost OOF RMSE:\", rmse(y, oof_cat))\n",
    "\n",
    "    # ---------------------------\n",
    "    # Ridge baseline\n",
    "    # ---------------------------\n",
    "    print(\"\\nTraining Ridge baseline...\")\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(train_features)):\n",
    "        X_tr = train_features.iloc[tr_idx]\n",
    "        X_val = train_features.iloc[val_idx]\n",
    "        y_tr = y.iloc[tr_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "        clf = Ridge(alpha=20.0, random_state=SEED)\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        oof_ridge[val_idx] = clf.predict(X_val)\n",
    "        pred_ridge += clf.predict(test_features) / NFOLD\n",
    "        print(f\"Fold {fold+1} Ridge RMSE: {rmse(y_val, oof_ridge[val_idx]):.5f}\")\n",
    "    print(\"Ridge OOF RMSE:\", rmse(y, oof_ridge))\n",
    "\n",
    "    # ---------------------------\n",
    "    # Stacking meta-learner\n",
    "    # ---------------------------\n",
    "    print(\"\\nStacking meta-learner (Ridge)...\")\n",
    "    stack_oof_list = [oof_lgb, oof_xgb, oof_ridge]\n",
    "    stack_pred_list = [pred_lgb, pred_xgb, pred_ridge]\n",
    "    if use_catboost:\n",
    "        stack_oof_list.append(oof_cat)\n",
    "        stack_pred_list.append(pred_cat)\n",
    "\n",
    "    X_oof = np.vstack(stack_oof_list).T\n",
    "    X_test_meta = np.vstack(stack_pred_list).T\n",
    "\n",
    "    meta_oof = np.zeros(n_train)\n",
    "    meta_pred = np.zeros(n_test)\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(X_oof)):\n",
    "        X_tr = X_oof[tr_idx]\n",
    "        X_val = X_oof[val_idx]\n",
    "        y_tr = y.iloc[tr_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "        m = Ridge(alpha=5.0, random_state=SEED)\n",
    "        m.fit(X_tr, y_tr)\n",
    "        meta_oof[val_idx] = m.predict(X_val)\n",
    "        meta_pred += m.predict(X_test_meta) / NFOLD\n",
    "        print(f\"Fold {fold+1} Meta RMSE: {rmse(y_val, meta_oof[val_idx]):.5f}\")\n",
    "    print(\"Meta OOF RMSE:\", rmse(y, meta_oof))\n",
    "\n",
    "    # ---------------------------\n",
    "    # Final submission\n",
    "    # ---------------------------\n",
    "    final_preds_log = meta_pred\n",
    "    final_preds = np.expm1(final_preds_log)\n",
    "    submission = pd.DataFrame({\"Id\": test_ID, \"SalePrice\": final_preds})\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"\\nWrote submission.csv  ready to upload to Kaggle\")\n",
    "    print(\"Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 868283,
     "sourceId": 5407,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 320.650739,
   "end_time": "2025-12-09T12:16:11.614629",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-09T12:10:50.963890",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
